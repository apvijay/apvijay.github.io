<html>

<head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-131122962-1"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-131122962-1');
    </script>

    <link rel="stylesheet" href="css/style.css">
    <link href='https://fonts.googleapis.com/css?family=Source+Sans+Pro' rel='stylesheet' type='text/css'>
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
    <base target="_blank">
    <title>
        Vijay Rengarajan
    </title>
</head>

<body>
    <div class="container">

    <h2>Photosequencing of Motion Blur using Short and Long Exposures</h2>
    Vijay Rengarajan, Shuo Zhao, Ruiwen Zhen, John Glotzbach, Hamid Sheikh, and Aswin Sankaranarayanan<br>
    NTIRE Workshop, CVPR 2020<br>

    <br>

    <table class="col-chg">
        <tr class="col-chg">
            <td><img class="page-img" src="img/photoseq/0.png"></td>
            <td><img class="page-img" src="img/photoseq/b.png"></td>
            <td><img class="page-img" src="img/photoseq/1.png"></td>
            <td><img class="page-img" src="img/photoseq/jellyfish.gif"></td>
        </tr>
        <tr class="col-chg">
            <td style="text-align:center">Short exposure</td>
            <td style="text-align:center">Long exposure</td>
            <td style="text-align:center">Short exposure</td>
            <td style="text-align:center">Our Photosequencing Output</td>
        </tr>
    </table>

    <h2>Abstract</h2>
    <hr>
    <p>
Photosequencing aims to transform a motion blurred image to a sequence of sharp images.  This problem is challenging  due  to  the  inherent  ambiguities in temporal ordering as well as the recovery of lost spatial textures due to blur. Adopting a computational photography approach, we propose to capture two short exposure images, along with the original blurred long exposure image to aid in the aforementioned challenges. Post-capture, we recover the sharp photosequence  using a novel blur decomposition strategy that recursively splits the long exposure image into smaller exposure intervals. We validate the approach by capturing a variety of scenes with interesting motions using machine vision cameras programmed to capture short and long exposure sequences. Our experimental results show that the proposed method resolves both fast and fine motions better than prior works.
<br>

<br>

<h2>Video</h2>
<hr>
<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/xosPuXJriw8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<br>
<br>

<h2>Publication</h2>
<hr>
Photosequencing of Motion Blur using Short and Long Exposures<br>
Vijay Rengarajan, Shuo Zhao, Ruiwen Zhen, John Glotzbach, Hamid Sheikh, and Aswin Sankaranarayanan<br>
NTIRE Workshop, CVPR 2020<br>
<a href="pdf/2020_cvprw.pdf">Paper</a><br>

<br>
